{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arasu\\Workspace\\Projects\\GenAI\\10.STB-6000_chat\\vnev\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from transformers import  pipeline\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "model = \"C:/Users/arasu/Workspace/Projects/GenAI/models/MBZUAILaMini-Flan-T5-248M/\"\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(model,truncation=True)\n",
    "base_model = T5ForConditionalGeneration.from_pretrained(model)\n",
    "\n",
    "pipe = pipeline(\n",
    "        'text2text-generation',\n",
    "        # 'summarization',\n",
    "        model = base_model,\n",
    "        tokenizer = tokenizer,\n",
    "        max_length = 500,\n",
    "        do_sample = True,\n",
    "        temperature = 0.5,\n",
    "        top_p= 0.95\n",
    "    )\n",
    "llm = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text = []\n",
    "\n",
    "# loader = PyPDFLoader(\"/content/STB-6000_user_manual_texts.pdf\")\n",
    "# text.extend(loader.load())\n",
    "loader = TextLoader(\"C:/Users/arasu/Workspace/Projects/GenAI/10.STB-6000_chat/manual/STB-6000_USER_MANUAL.txt\")\n",
    "text.extend(loader.load())\n",
    "text_spiltter = RecursiveCharacterTextSplitter(chunk_size = 1400, chunk_overlap = 350)\n",
    "text_documents = text_spiltter.split_documents(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content=\"The STB-6000 USER MANUAL provides clear instructions for setting up your HD Set Top Box. In the package, you will find the STB-6000 HD Set Top Box, a remote control, an AV Cable (Composite RCA), and, of course, the User Manual (which is the document you're reading). To begin, installing the batteries in the remote control is the first step. Simply remove the battery compartment cover located on the back of the remote control, insert the two AAA batteries provided, ensuring the correct polarity as indicated in the compartment. Once the batteries are in place, put the cover back on and ensure it locks securely. This ensures your remote control is ready for use. The User Manual offers detailed yet straightforward guidance, making the setup process easy for users to follow and understand.\", metadata={'source': 'C:/Users/arasu/Workspace/Projects/GenAI/10.STB-6000_chat/manual/STB-6000_USER_MANUAL.txt'})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_documents[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "embedding = HuggingFaceBgeEmbeddings(model_name=\"C:/Users/arasu/Workspace/Projects/GenAI/embeddings/hkunlp_instructor-large/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "db_path = \"text_vector_db\"\n",
    "text_vector = Chroma(persist_directory=db_path,embedding_function=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = text_vector.as_retriever(search_kwargs={\"k\":2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text_documents' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mretrievers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BM25Retriever, EnsembleRetriever\n\u001b[1;32m----> 2\u001b[0m bm25_retriever \u001b[38;5;241m=\u001b[39m BM25Retriever\u001b[38;5;241m.\u001b[39mfrom_documents(\u001b[43mtext_documents\u001b[49m)\n\u001b[0;32m      3\u001b[0m ensemble_retriever \u001b[38;5;241m=\u001b[39m EnsembleRetriever(retrievers\u001b[38;5;241m=\u001b[39m[retriever, bm25_retriever], weights\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'text_documents' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "bm25_retriever = BM25Retriever.from_documents(text_documents)\n",
    "ensemble_retriever = EnsembleRetriever(retrievers=[retriever, bm25_retriever], weights=[0.5, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "template = \"\"\"\n",
    "    You are friendly customer care assistant trying to help user on the context provided.\\\n",
    "    give the answer in a very detailed manner.\\\n",
    "    if the answer is not found in the context then reply \"I Dont Know\".\\\n",
    "    context: {context}\n",
    "    question: {question}\n",
    "    \"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"context\", \"question\"])\n",
    "\n",
    "chain_type_kwargs = {\"prompt\": prompt}\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm = llm,\n",
    "    chain_type = \"stuff\",\n",
    "    retriever = retriever,\n",
    "    input_key=\"query\",\n",
    "    chain_type_kwargs=chain_type_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arasu\\Workspace\\Projects\\GenAI\\10.STB-6000_chat\\vnev\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'what are all the ports available in the rear panel of the setup box?', 'result': 'The ports available in the rear panel of the setup box are Antenna In (RF IN), Antenna Loop Through (RF OUT), HDMI Output, Video Output, and two Audio Left/Right outputs.'}\n"
     ]
    }
   ],
   "source": [
    "result = qa(\"how to install batteries?\")\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
